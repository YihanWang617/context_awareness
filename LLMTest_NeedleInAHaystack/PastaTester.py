from typing import Optional
from HuggingfaceTester import HuggingfaceTester
import numpy as np
import torch
import os
from typing import List
from jsonargparse import CLI
import asyncio
from pastalib.pasta import PASTA
import sys
sys.path.append('../')
from UserSteeredWrapper import UserSteeredWrapper

class PastaTester(HuggingfaceTester):
    
    # PASTA_HEAD_CONFIGS = {
    #     "tinyllama": {k: None for k in range(22)},
    #     "llama-2": {k: None for k in range(32)},
    #     "llama-3": {k: None for k in range(32)},
    # }

    # PASTA_HEAD_CONFIGS = {
    #     "tinyllama": {k: None for k in range(22)},
    #     "llama-2": {k: None for k in range(32)},
    #     "llama-3": {0: [21, 9, 8, 11, 15], 1: [ 9, 12, 28, 29, 8], 2: [ 6, 14, 19, 22, 15], 3: [ 9, 20, 22, 21, 0], 4: [15, 10, 1, 19, 16], 5: [17, 7, 1, 24, 4], 6: [31, 26, 25, 9, 6], 7: [26, 13, 15, 22, 25], 8: [ 8, 1, 9, 31, 11], 9: [15, 16, 2, 12, 3], 10: [14, 29, 1, 31, 13], 11: [18, 6, 15, 9, 13], 12: [ 9, 5, 21, 10, 15], 13: [ 5, 21, 8, 4, 18], 14: [29, 5, 12, 31, 22], 15: [11, 21, 26, 29, 30], 16: [ 0, 19, 25, 26, 1], 17: [31, 27, 26, 24, 29], 18: [ 9, 0, 8, 22, 20], 19: [23, 13, 3, 14, 9], 20: [30, 9, 26, 12, 14], 21: [ 8, 11, 1, 14, 26], 22: [10, 11, 27, 29, 8], 23: [19, 20, 25, 27, 22], 24: [24, 23, 3, 18, 27], 25: [17, 18, 2, 6, 5],26: [27, 15, 6, 19, 30],27: [ 4, 5, 28, 7, 16], 28: [15, 20, 23, 18, 0], 29: [31, 8, 11, 9, 16], 30:[17, 21, 18, 27, 2], 31:[30, 28, 7, 29, 21]},
    # }
    # PASTA_HEAD_CONFIGS = {
    #     "tinyllama": {k: None for k in range(22)},
    #     "llama-2": {k: None for k in range(32)},
    #     "llama-3": {0: [15], 1: [8], 2: [15], 3: [0], 4: [16], 5: [4], 6: [6], 7: [25], 8: [11], 9: [3], 10: [13], 11: [13], 12: [15], 13: [18], 14: [22], 15: [30], 16: [1], 17: [29], 18: [20], 19: [9], 20: [14], 21: [26], 22: [8], 23: [22], 24: [27], 25: [5],26: [30],27: [6], 28: [0], 29: [16], 30:[2], 31:[21]},
    # }

    # PASTA_HEAD_CONFIGS = {
    #     "tinyllama": {k: None for k in range(22)},
    #     "llama-2-7b": {0: [2, 13, 1, 22, 4, 30, 21, 24, 7, 11], 1: [28, 4, 30, 27, 20, 18, 26, 11, 8, 9], 2: [5, 17, 1, 13, 3, 21, 22, 15, 23, 25], 3: [28, 6, 1, 0, 7, 8, 9, 26, 17, 31], 4: [16, 12, 26, 20, 14, 21, 2, 8, 5, 1], 5: [29, 12, 4, 2, 5, 21, 23, 13, 1, 20], 6: [25, 29, 7, 18, 28, 13, 21, 12, 9, 17], 7: [4, 6, 21, 8, 0, 29, 14, 12, 20, 28], 8: [4, 13, 5, 23, 29, 6, 24, 22, 3, 25], 9: [7, 31, 18, 6, 25, 0, 23, 20, 30, 12], 10: [8, 12, 30, 11, 2, 31, 4, 23, 29, 19], 11: [7, 14, 24, 31, 30, 15, 8, 9, 17, 19], 12: [18, 21, 10, 16, 9, 14, 13, 4, 25, 11], 13: [3, 13, 18, 1, 23, 31, 2, 30, 4, 9], 14: [27, 24, 4, 2, 15, 20, 19, 3, 9, 18], 15: [29, 19, 27, 31, 24, 14, 10, 9, 5, 17], 16: [6, 2, 20, 17, 13, 18, 3, 5, 19, 31], 17: [31, 1, 8, 24, 11, 10, 30, 0, 18, 13], 18: [28, 1, 31, 15, 12, 23, 27, 9, 10, 30], 19: [18, 13, 21, 12, 14, 19, 5, 10, 4, 15], 20: [27, 5, 7, 11, 25, 10, 28, 0, 29, 30], 21: [0, 1, 29, 31, 16, 27, 4, 13, 10, 30], 22: [27, 24, 16, 6, 30, 19, 11, 2, 31, 23], 23: [12, 0, 20, 7, 28, 17, 8, 29, 9, 31], 24: [24, 3, 16, 15, 5, 4, 1, 29, 17, 30], 25: [5, 29, 17, 0, 21, 24, 3, 16, 28, 11], 26: [10, 26, 28, 21, 24, 3, 14, 25, 19, 27], 27: [15, 18, 22, 14, 12, 27, 7, 25, 2, 4], 28: [15, 4, 8, 14, 11, 18, 17, 9, 13, 7], 29: [11, 10, 21, 15, 5, 2, 19, 18, 9, 13], 30: [1, 29, 25, 22, 15, 8, 26, 27, 9, 14], 31: [29, 19, 17, 6, 9, 25, 15, 16, 24, 22]},
    #     "llama-2-13b": {k: None for k in range(40)},
    #     "llama-3": {0: [17, 13, 23, 22, 3, 21, 11, 8, 9, 15], 1: [19, 12, 10, 22, 9, 2, 31, 29, 28, 8], 2: [28, 21, 5, 6, 10, 4, 19, 14, 22, 15], 3: [2, 28, 23, 8, 20, 29, 22, 9, 21, 0], 4: [8, 5, 22, 28, 6, 10, 1, 15, 19, 16], 5: [27, 8, 5, 25, 17, 18, 1, 24, 7, 4], 6: [20, 14, 24, 2, 26, 6, 9, 28, 25, 31], 7: [23, 10, 24, 21, 7, 6, 26, 13, 22, 25], 8: [10, 3, 30, 2, 1, 18, 31, 8, 9, 11], 9: [21, 23, 2, 15, 29, 12, 17, 16, 19, 3], 10: [26, 19, 24, 29, 31, 27, 25, 1, 18, 13], 11: [0, 7, 6, 24, 9, 13, 14, 3, 18, 2], 12: [26, 11, 16, 1, 31, 23, 8, 15, 9, 10], 13: [10, 16, 5, 21, 1, 23, 3, 17, 8, 18], 14: [5, 20, 30, 23, 2, 3, 29, 22, 31, 12], 15: [4, 23, 16, 25, 8, 21, 11, 29, 5, 30], 16: [4, 8, 6, 28, 0, 19, 26, 25, 20, 1], 17: [15, 31, 14, 5, 7, 13, 29, 27, 28, 24], 18: [14, 28, 12, 23, 0, 24, 9, 22, 8, 20], 19: [15, 8, 10, 2, 23, 20, 9, 3, 14, 13], 20: [13, 3, 25, 0, 23, 12, 24, 30, 26, 14], 21: [23, 0, 3, 18, 1, 26, 11, 31, 8, 2], 22: [4, 17, 15, 27, 11, 5, 12, 29, 14, 8], 23: [28, 24, 19, 20, 18, 17, 1, 0, 27, 22], 24: [20, 16, 26, 18, 14, 12, 17, 24, 13, 27], 25: [13, 17, 12, 19, 6, 1, 0, 2, 18, 5],26: [15, 2, 13, 27, 17, 23, 3, 6, 30, 19],27: [15, 21, 8, 13, 11, 14, 28, 16, 5, 7], 28: [3, 15, 11, 18, 10, 30, 0, 23, 21, 20], 29: [30, 23, 11, 28, 29, 9, 10, 31, 8, 16], 30:[15, 12, 1, 17, 27, 18, 26, 0, 9, 2], 31:[16, 31, 20, 2, 27, 30, 28, 29, 21, 7]},
    # }

    PASTA_HEAD_CONFIGS = {
        "tinyllama": {k: None for k in range(22)},
        "llama-2-7b": {0: [20, 23, 2, 22, 11, 13, 24, 30, 7, 21], 1: [28, 23, 20, 27, 17, 11, 18, 26, 8, 9], 2: [6, 8, 13, 15, 3, 23, 25, 26, 22, 21], 3: [23, 21, 28, 27, 0, 26, 9, 8, 17, 31], 4: [24, 12, 26, 14, 20, 8, 21, 2, 5, 1], 5: [6, 2, 21, 12, 4, 13, 20, 23, 1, 3], 6: [7, 9, 29, 2, 25, 18, 13, 21, 16, 17], 7: [28, 21, 29, 13, 0, 14, 20, 12, 6, 10], 8: [7, 29, 23, 31, 24, 3, 22, 26, 5, 25], 9: [26, 22, 7, 31, 0, 20, 6, 21, 12, 30], 10: [31, 8, 11, 24, 0, 18, 23, 19, 4, 29], 11: [7, 24, 28, 31, 30, 19, 17, 9, 15, 14], 12: [8, 1, 22, 9, 10, 13, 16, 14, 11, 4], 13: [3, 22, 8, 17, 4, 18, 2, 9, 23, 30], 14: [19, 15, 9, 1, 2, 29, 7, 3, 24, 18], 15: [8, 31, 9, 17, 19, 24, 27, 5, 10, 14], 16: [2, 14, 4, 20, 13, 3, 18, 5, 30, 19], 17: [2, 1, 11, 0, 10, 9, 18, 13, 22, 30], 18: [1, 5, 16, 31, 15, 10, 23, 12, 9, 30], 19: [28, 31, 13, 14, 10, 8, 4, 19, 6, 15], 20: [23, 10, 0, 16, 12, 5, 11, 3, 30, 29], 21: [15, 31, 9, 1, 4, 27, 10, 16, 13, 30], 22: [8, 3, 31, 11, 19, 30, 16, 27, 23, 22], 23: [2, 25, 5, 29, 28, 17, 6, 20, 8, 31], 24: [25, 24, 3, 16, 15, 4, 1, 30, 11, 17], 25: [2, 16, 30, 5, 4, 21, 0, 28, 3, 11], 26: [3, 26, 15, 21, 24, 25, 10, 14, 19, 27], 27: [14, 10, 1, 23, 25, 16, 4, 2, 22, 7], 28: [11, 8, 18, 25, 14, 17, 4, 13, 9, 7], 29: [15, 2, 28, 5, 17, 19, 9, 10, 18, 13], 30: [27, 25, 12, 19, 4, 26, 15, 14, 9, 29], 31: [29, 17, 16, 6, 12, 25, 2, 24, 15, 22]},
        "llama-2-13b": {0: [2, 22, 0, 4, 9, 6, 7, 1, 10, 20], 1: [17, 34, 36, 8, 15, 31, 19, 35, 30, 26], 2: [24, 4, 7, 23, 30, 36, 38, 19, 16, 9], 3: [23, 0, 5, 39, 22, 14, 8, 15, 24, 20], 4: [31, 32, 10, 35, 13, 9, 5, 1, 20, 33], 5: [28, 21, 18, 24, 39, 37, 17, 3, 33, 27], 6: [31, 6, 30, 22, 37, 36, 12, 23, 20, 39], 7: [23, 14, 3, 28, 33, 36, 10, 12, 15, 4], 8: [9, 22, 38, 16, 17, 33, 24, 20, 4, 35], 9: [36, 3, 20, 21, 37, 22, 28, 33, 34, 6], 10: [30, 29, 6, 5, 9, 24, 25, 23, 31, 18], 11: [21, 17, 4, 12, 1, 25, 32, 35, 5, 37], 12: [7, 8, 24, 36, 21, 1, 31, 18, 16, 5], 13: [14, 4, 36, 17, 12, 13, 11, 21, 24, 23], 14: [8, 25, 1, 39, 33, 13, 0, 23, 4, 20], 15: [24, 6, 34, 15, 4, 17, 20, 25, 7, 39], 16: [9, 25, 11, 21, 1, 31, 33, 30, 3, 2], 17: [21, 30, 35, 6, 16, 4, 19, 3, 5, 2], 18: [2, 18, 34, 37, 22, 19, 16, 6, 35, 14], 19: [5, 16, 29, 8, 1, 27, 0, 33, 3, 4], 20: [11, 8, 36, 18, 0, 1, 24, 25, 23, 34], 21: [4, 27, 39, 22, 37, 25, 14, 1, 6, 5], 22: [27, 16, 34, 2, 8, 29, 5, 33, 6, 1], 23: [18, 26, 33, 15, 1, 9, 38, 0, 23, 13], 24: [19, 4, 29, 21, 2, 17, 25, 24, 26, 16], 25: [0, 21, 25, 26, 30, 33, 36, 9, 18, 4], 26: [21, 36, 7, 22, 24, 30, 15, 5, 29, 13], 27: [39, 29, 12, 5, 14, 30, 18, 1, 33, 36], 28: [21, 38, 31, 10, 8, 17, 5, 9, 20, 22], 29: [33, 20, 15, 34, 28, 24, 4, 2, 22, 31], 30: [35, 6, 1, 28, 10, 38, 36, 5, 24, 14], 31: [6, 37, 39, 2, 18, 9, 36, 21, 1, 27], 32: [27, 24, 4, 14, 12, 32, 33, 35, 19, 25], 33: [30, 11, 23, 12, 7, 0, 34, 25, 24, 18], 34: [21, 27, 34, 38, 7, 10, 23, 8, 32, 2], 35: [21, 6, 9, 38, 24, 34, 26, 17, 30, 4], 36: [30, 21, 27, 32, 23, 29, 3, 16, 2, 20], 37: [30, 25, 5, 24, 15, 0, 16, 21, 4, 8], 38: [16, 39, 7, 2, 29, 13, 37, 9, 28, 12], 39: [37, 25, 33, 1, 6, 10, 19, 24, 29, 8]},
        "llama-3": {0: [17, 13, 23, 22, 3, 21, 11, 8, 9, 15], 1: [19, 12, 10, 22, 9, 2, 31, 29, 28, 8], 2: [28, 21, 5, 6, 10, 4, 19, 14, 22, 15], 3: [2, 28, 23, 8, 20, 29, 22, 9, 21, 0], 4: [8, 5, 22, 28, 6, 10, 1, 15, 19, 16], 5: [27, 8, 5, 25, 17, 18, 1, 24, 7, 4], 6: [20, 14, 24, 2, 26, 6, 9, 28, 25, 31], 7: [23, 10, 24, 21, 7, 6, 26, 13, 22, 25], 8: [10, 3, 30, 2, 1, 18, 31, 8, 9, 11], 9: [21, 23, 2, 15, 29, 12, 17, 16, 19, 3], 10: [26, 19, 24, 29, 31, 27, 25, 1, 18, 13], 11: [0, 7, 6, 24, 9, 13, 14, 3, 18, 2], 12: [26, 11, 16, 1, 31, 23, 8, 15, 9, 10], 13: [10, 16, 5, 21, 1, 23, 3, 17, 8, 18], 14: [5, 20, 30, 23, 2, 3, 29, 22, 31, 12], 15: [4, 23, 16, 25, 8, 21, 11, 29, 5, 30], 16: [4, 8, 6, 28, 0, 19, 26, 25, 20, 1], 17: [15, 31, 14, 5, 7, 13, 29, 27, 28, 24], 18: [14, 28, 12, 23, 0, 24, 9, 22, 8, 20], 19: [15, 8, 10, 2, 23, 20, 9, 3, 14, 13], 20: [13, 3, 25, 0, 23, 12, 24, 30, 26, 14], 21: [23, 0, 3, 18, 1, 26, 11, 31, 8, 2], 22: [4, 17, 15, 27, 11, 5, 12, 29, 14, 8], 23: [28, 24, 19, 20, 18, 17, 1, 0, 27, 22], 24: [20, 16, 26, 18, 14, 12, 17, 24, 13, 27], 25: [13, 17, 12, 19, 6, 1, 0, 2, 18, 5],26: [15, 2, 13, 27, 17, 23, 3, 6, 30, 19],27: [15, 21, 8, 13, 11, 14, 28, 16, 5, 7], 28: [3, 15, 11, 18, 10, 30, 0, 23, 21, 20], 29: [30, 23, 11, 28, 29, 9, 10, 31, 8, 16], 30:[15, 12, 1, 17, 27, 18, 26, 0, 9, 2], 31:[16, 31, 20, 2, 27, 30, 28, 29, 21, 7]},
    }
    
    @staticmethod
    def get_pasta_head_config(model_name):
        for k, v in PastaTester.PASTA_HEAD_CONFIGS.items():
            if k in model_name.lower():
                return v
        return None

    def __init__(self, **kwargs):
        self.alpha = kwargs.pop("alpha")
        assert (self.alpha <= 1) and (self.alpha > 0)
        super().__init__(**kwargs)
        head_config = self.get_pasta_head_config(self.model_name)
        if head_config is None:
            raise ValueError(f"Pasta head config not found for {self.model_name}. Populate PASTA_HEAD_CONFIGS with retrieval heads for this model before running HayStack with Pasta intervention.")
        self.wrapped_model = UserSteeredWrapper(head_config, self.model_to_test, self.tokenizer, self.alpha)

    def generate(self, conversation_history, context=None, max_new_tokens=100):
        # print(prompt)
        
        output = self.wrapped_model.generate(conversation_history, context, max_new_tokens=max_new_tokens)
        
        return output

    async def get_response_from_model(self, prompt_context):
        # generate_ids = self.model_to_test.generate(inputs.input_ids, max_new_tokens=60, pad_token_id=self.tokenizer.pad_token_id)
        # generate_ids = generate_ids[:, inputs["input_ids"].shape[1]:]
        prompt, context = prompt_context
        generate_ids = self.generate(prompt, context, max_new_tokens=100)
        response = self.tokenizer.decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)

        return response

    def get_prompt(self, context, return_context=True):
        prompt, context = super().get_prompt(context, return_context=True)
        if return_context:
            return prompt, context
        else:
            return prompt

def main(model_name: str=None, template: str='default', needle_name: str="SF", evaluation_method: str="substring_match", 
         alpha: float=0.01, context_lengths_min: int=200, context_lengths_max: int=4000, 
         context_lengths: Optional[List[int]]=None, document_depths: Optional[List[int]]=None,
         add_hint: bool=False, save_model_suffix: Optional[str]=None):

    assert model_name is not None
    assert template in ["raw", "default"]

    if save_model_suffix is None:
        save_model_suffix = str(alpha)

    tester = PastaTester(model_name=model_name, 
                         template=template,
                         evaluation_method=evaluation_method, 
                         alpha=alpha, 
                         context_lengths_min=context_lengths_min, 
                         context_lengths_max=context_lengths_max,
                         context_lengths=context_lengths,
                         document_depth_percents=document_depths,
                         needle_name=needle_name,
                         add_hint=add_hint,
                         save_model_suffix=save_model_suffix,
                         attn_implementation='eager')
    tester.start_test()

if __name__ == '__main__':
    CLI(main)
